{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Accessing this dataset with my gdrive because I had to clean the data by hand and reupload to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:39:51.524814Z",
     "iopub.status.busy": "2025-02-25T20:39:51.524590Z",
     "iopub.status.idle": "2025-02-25T20:40:27.975863Z",
     "shell.execute_reply": "2025-02-25T20:40:27.974946Z",
     "shell.execute_reply.started": "2025-02-25T20:39:51.524793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "https://drive.google.com/drive/folders/1RpHYaTL-r22AUqhDhQRjQAxm0MzxGERf?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:40:31.735209Z",
     "iopub.status.busy": "2025-02-25T20:40:31.734934Z",
     "iopub.status.idle": "2025-02-25T20:40:32.655346Z",
     "shell.execute_reply": "2025-02-25T20:40:32.654678Z",
     "shell.execute_reply.started": "2025-02-25T20:40:31.735189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: Training_images.zip, File ID: 1LPRXi81BdrLT4u7UE5etSqg-JfwjUkNk\n",
      "File Name: Test_images.zip, File ID: 1Q7IgKDLd1270N9x1mxCrcVPm81IoX6kK\n",
      "File Name: Validation_images.zip, File ID: 1__8UfmITWqJ8PJbVCK33pbwsYvz9YZKh\n"
     ]
    }
   ],
   "source": [
    "folder_id = '1RpHYaTL-r22AUqhDhQRjQAxm0MzxGERf'  \n",
    "\n",
    "file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n",
    "\n",
    "for file in file_list:\n",
    "    print(f\"File Name: {file['title']}, File ID: {file['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:40:36.383111Z",
     "iopub.status.busy": "2025-02-25T20:40:36.382805Z",
     "iopub.status.idle": "2025-02-25T20:41:01.683179Z",
     "shell.execute_reply": "2025-02-25T20:41:01.682204Z",
     "shell.execute_reply.started": "2025-02-25T20:40:36.383085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Training_images.zip...\n",
      "Downloaded Training_images.zip successfully!\n",
      "Downloading Test_images.zip...\n",
      "Downloaded Test_images.zip successfully!\n",
      "Downloading Validation_images.zip...\n",
      "Downloaded Validation_images.zip successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('downloaded_files', exist_ok=True)\n",
    "\n",
    "for file in file_list:\n",
    "    if file['title'].endswith('.zip'): \n",
    "        print(f\"Downloading {file['title']}...\")\n",
    "        downloaded = drive.CreateFile({'id': file['id']})\n",
    "        downloaded.GetContentFile(os.path.join('downloaded_files', file['title']))\n",
    "        print(f\"Downloaded {file['title']} successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can Ignore the blocks above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:41:04.664294Z",
     "iopub.status.busy": "2025-02-25T20:41:04.664015Z",
     "iopub.status.idle": "2025-02-25T20:41:10.650554Z",
     "shell.execute_reply": "2025-02-25T20:41:10.649834Z",
     "shell.execute_reply.started": "2025-02-25T20:41:04.664272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:41:27.771490Z",
     "iopub.status.busy": "2025-02-25T20:41:27.770984Z",
     "iopub.status.idle": "2025-02-25T20:41:29.650640Z",
     "shell.execute_reply": "2025-02-25T20:41:29.649954Z",
     "shell.execute_reply.started": "2025-02-25T20:41:27.771435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "extract_zip('/kaggle/working/downloaded_files/Training_images.zip', '/kaggle/working/train')\n",
    "extract_zip('/kaggle/working/downloaded_files/Validation_images.zip', '/kaggle/working/val')\n",
    "extract_zip('/kaggle/working/downloaded_files/Test_images.zip', '/kaggle/working/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating positive and negative paths for our Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T20:44:40.618181Z",
     "iopub.status.busy": "2025-02-25T20:44:40.617879Z",
     "iopub.status.idle": "2025-02-25T20:44:41.374955Z",
     "shell.execute_reply": "2025-02-25T20:44:41.374130Z",
     "shell.execute_reply.started": "2025-02-25T20:44:40.618161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "positive_path = '/kaggle/working/train/Training_images/Positive'\n",
    "negative_path = '/kaggle/working/train/Training_images/Negative'\n",
    "balanced_train_path = '/kaggle/working/balanced_training'\n",
    "\n",
    "os.makedirs(balanced_train_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(balanced_train_path, 'positive'), exist_ok=True)\n",
    "os.makedirs(os.path.join(balanced_train_path, 'negative'), exist_ok=True)\n",
    "\n",
    "# Select 2304 positive images randomly\n",
    "# Here im matching the number of pos and neg images for better accuracy\n",
    "positive_images = [os.path.join(positive_path, f) for f in os.listdir(positive_path) \n",
    "                  if f.endswith('.jpg') or f.endswith('.png')]\n",
    "random.shuffle(positive_images)\n",
    "selected_positive = positive_images[:2304]\n",
    "\n",
    "for img in selected_positive:\n",
    "    shutil.copy(img, os.path.join(balanced_train_path, 'positive'))\n",
    "\n",
    "negative_images = [os.path.join(negative_path, f) for f in os.listdir(negative_path) \n",
    "                   if f.endswith('.jpg') or f.endswith('.png')]\n",
    "for img in negative_images:\n",
    "    shutil.copy(img, os.path.join(balanced_train_path, 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T21:46:38.266676Z",
     "iopub.status.busy": "2025-02-24T21:46:38.266316Z",
     "iopub.status.idle": "2025-02-24T21:46:38.271656Z",
     "shell.execute_reply": "2025-02-24T21:46:38.270961Z",
     "shell.execute_reply.started": "2025-02-24T21:46:38.266648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting to generate more pictures based on our current data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:02:44.269193Z",
     "iopub.status.busy": "2025-02-24T22:02:44.268847Z",
     "iopub.status.idle": "2025-02-24T22:02:44.275497Z",
     "shell.execute_reply": "2025-02-24T22:02:44.274492Z",
     "shell.execute_reply.started": "2025-02-24T22:02:44.269167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.3),\n",
    "    transforms.RandomAdjustSharpness(2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:02:46.588341Z",
     "iopub.status.busy": "2025-02-24T22:02:46.588040Z",
     "iopub.status.idle": "2025-02-24T22:02:46.611653Z",
     "shell.execute_reply": "2025-02-24T22:02:46.610955Z",
     "shell.execute_reply.started": "2025-02-24T22:02:46.588317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder('/kaggle/working/train/Training_images', transform=train_transform)\n",
    "val_dataset = ImageFolder('/kaggle/working/val/Validation_images', transform=val_test_transform)\n",
    "test_dataset = ImageFolder('/kaggle/working/test/Test_images', transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:03:24.572078Z",
     "iopub.status.busy": "2025-02-24T22:03:24.571746Z",
     "iopub.status.idle": "2025-02-24T22:03:24.579613Z",
     "shell.execute_reply": "2025-02-24T22:03:24.578722Z",
     "shell.execute_reply.started": "2025-02-24T22:03:24.572050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=[0, 1], \n",
    "    y=train_dataset.targets\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                       num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using resnet50 for our model. I personally chose this model because we don't have a huge amount of data and hence the modeling progress shouldn't take long and we can achieve better accuracy. Else we can just go for less layers like resnet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:03:27.615931Z",
     "iopub.status.busy": "2025-02-24T22:03:27.615614Z",
     "iopub.status.idle": "2025-02-24T22:03:28.142672Z",
     "shell.execute_reply": "2025-02-24T22:03:28.141856Z",
     "shell.execute_reply.started": "2025-02-24T22:03:27.615904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "<ipython-input-51-9ae16284a56c>:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # For mixed precision\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replacing final layer with dropout\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Enhanced optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.75, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # Weight for positive class\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha * (1-pt)**self.gamma * ce_loss).mean()\n",
    "        return focal_loss\n",
    "\n",
    "criterion = FocalLoss(alpha=0.85)  # Prioritize positive class\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                factor=0.1, patience=3)\n",
    "scaler = torch.cuda.amp.GradScaler()  # For mixed precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:03:31.427020Z",
     "iopub.status.busy": "2025-02-24T22:03:31.426724Z",
     "iopub.status.idle": "2025-02-24T22:07:25.415680Z",
     "shell.execute_reply": "2025-02-24T22:07:25.414668Z",
     "shell.execute_reply.started": "2025-02-24T22:03:31.426982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:19<00:00,  3.68it/s, loss=0.0989]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Val Acc: 0.7400\n",
      "Epoch 1 Summary:\n",
      "Train Loss: 0.1494 | Val Acc: 0.7400\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.64it/s, loss=0.0898]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary:\n",
      "Train Loss: 0.1129 | Val Acc: 0.7100\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.53it/s, loss=0.0996]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Val Acc: 0.7800\n",
      "Epoch 3 Summary:\n",
      "Train Loss: 0.1027 | Val Acc: 0.7800\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.55it/s, loss=0.101] \n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary:\n",
      "Train Loss: 0.0944 | Val Acc: 0.7400\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.63it/s, loss=0.0794]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Val Acc: 0.7900\n",
      "Epoch 5 Summary:\n",
      "Train Loss: 0.0916 | Val Acc: 0.7900\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.61it/s, loss=0.0857]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved! Val Acc: 0.8600\n",
      "Epoch 6 Summary:\n",
      "Train Loss: 0.0846 | Val Acc: 0.8600\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.57it/s, loss=0.0749]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Summary:\n",
      "Train Loss: 0.0810 | Val Acc: 0.8300\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.58it/s, loss=0.116] \n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Summary:\n",
      "Train Loss: 0.1172 | Val Acc: 0.5300\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.62it/s, loss=0.0994]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Summary:\n",
      "Train Loss: 0.1062 | Val Acc: 0.8000\n",
      "Current LR: 0.001000\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.59it/s, loss=0.0988]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Summary:\n",
      "Train Loss: 0.0992 | Val Acc: 0.7500\n",
      "Current LR: 0.000100\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/73 [00:00<?, ?it/s]<ipython-input-52-d28880c93c9f>:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 73/73 [00:20<00:00,  3.58it/s, loss=0.0893]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "epochs_without_improve = 0\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(50):  \n",
    "    print(f'\\nEpoch {epoch+1}/50')\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Val\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Validating'):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_accuracies.append(val_acc)\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_without_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'New best model saved! Val Acc: {val_acc:.4f}')\n",
    "    else:\n",
    "        epochs_without_improve += 1\n",
    "        if epochs_without_improve >= patience:\n",
    "            print(f'\\nEarly stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    print(f'Epoch {epoch+1} Summary:')\n",
    "    print(f'Train Loss: {epoch_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "    print(f'Current LR: {optimizer.param_groups[0][\"lr\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Early stopping for when the model isn't improving to save time and avoid overfitting our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T22:16:48.489795Z",
     "iopub.status.busy": "2025-02-24T22:16:48.489385Z",
     "iopub.status.idle": "2025-02-24T22:16:53.002303Z",
     "shell.execute_reply": "2025-02-24T22:16:53.000899Z",
     "shell.execute_reply.started": "2025-02-24T22:16:48.489761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-b151588d2e69>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n",
      "Testing: 100%|██████████| 19/19 [00:04<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Metrics:\n",
      "Accuracy: 0.9421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.95      0.99      0.97      1066\n",
      "    Positive       0.83      0.57      0.67       125\n",
      "\n",
      "    accuracy                           0.94      1191\n",
      "   macro avg       0.89      0.78      0.82      1191\n",
      "weighted avg       0.94      0.94      0.94      1191\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1051   15]\n",
      " [  54   71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Test evaluation\n",
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        positive_probs = probs[:, 1]  # Probability of CAD\n",
    "        \n",
    "        new_threshold = 0.7  # to reduce false positives\n",
    "        preds = (positive_probs > new_threshold).long()\n",
    "        \n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print('\\nFinal Test Metrics:')\n",
    "print(f'Accuracy: {accuracy_score(test_labels, test_preds):.4f}')\n",
    "print(classification_report(test_labels, test_preds, target_names=['Negative', 'Positive']))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T19:01:07.671089Z",
     "iopub.status.busy": "2025-05-13T19:01:07.670764Z",
     "iopub.status.idle": "2025-05-13T19:01:07.676410Z",
     "shell.execute_reply": "2025-05-13T19:01:07.675809Z",
     "shell.execute_reply.started": "2025-05-13T19:01:07.671065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Final Test Metrics (incase it's not shown in github):\n",
    "Accuracy: 0.9421\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Negative       0.95      0.99      0.97      1066\n",
    "    Positive       0.83      0.57      0.67       125\n",
    "\n",
    "    accuracy                           0.94      1191\n",
    "   macro avg       0.89      0.78      0.82      1191\n",
    "weighted avg       0.94      0.94      0.94      1191\n",
    "\n",
    "Confusion Matrix:\n",
    "[[1051   15]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see since we don't have enough positive cases for our data we have a 0.57 recall on our positive cases which means 43% of our positive cases are missed. hence this model isn't good for real life deployment unless we add more and equal data to it. but it's meant for practice anyways."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
